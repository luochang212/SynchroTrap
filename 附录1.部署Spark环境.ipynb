{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db95999e-cffc-40af-b478-345fb154d934",
   "metadata": {},
   "source": [
    "# 附录1：部署 Spark 环境\n",
    "\n",
    "运行 Spark 不需要大公司那样的 Hadoop, Hive, Spark 基建，在单机上也能运行。使用 Docker 是一个好方法。\n",
    "\n",
    "如果你不了解 Docker，请访问以下资源：\n",
    "\n",
    "- 下载：[Docker](https://www.docker.com/)\n",
    "- 文档：[Guides](https://docs.docker.com/guides/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285ecab",
   "metadata": {},
   "source": [
    "## 1. 使用 Docker 安装 Spark 环境\n",
    "\n",
    "新手常见的一个问题是，打开 Docker 却发现 Docker 无法使用。\n",
    "\n",
    "这大概率是因为 Docker 服务端没打开。Docker 是 客户端 / 服务端分离的。打开 Docker 应用只打开了 **客户端**，你还需要确保 **服务端** 也是开启状态。\n",
    "\n",
    "在命令行运行以下代码，以检查 Docker 服务端是否启用：\n",
    "\n",
    "```bash\n",
    "docker --version\n",
    "```\n",
    "\n",
    "### 1.1 下载 Docker 镜像\n",
    "\n",
    "把 [Dockerfile](https://github.com/jupyter/docker-stacks/blob/main/images/all-spark-notebook/Dockerfile) 复制到本地。然后打开命令行，来到 Dockerfile 所在目录，运行以下代码构建镜像：\n",
    "\n",
    "```bash\n",
    "docker build -t spark-notebook-image .\n",
    "```\n",
    "\n",
    "镜像构建完成后，你可以在客户端中查看镜像信息：\n",
    "\n",
    "![docker-app](./img/docker-app.png)\n",
    "\n",
    "> 注意，中国大陆无法直接下载 Docker 镜像，你需要一些特殊的网络技巧。\n",
    "\n",
    "### 1.2 启动一个 Docker 容器\n",
    "\n",
    "一旦镜像构建完成，你可以通过以下命令来启动一个容器：\n",
    "\n",
    "```bash\n",
    "# docker run -it --name <container-name> <image-name>\n",
    "# 运行选项：\n",
    "# -it: 用交互模式运行，这意味着你可以进入容器中\n",
    "# -d: 后台运行\n",
    "# -p <local-port>:<container-port>: 映射指定端口\n",
    "\n",
    "docker run -d --name spark-notebook-container -p 9999:8888 spark-notebook-image\n",
    "```\n",
    "\n",
    "> Docker 镜像与容器：\n",
    "> \n",
    "> - 镜像是可复制的，你可以在网上把别人的 Docker 镜像下载到本地\n",
    "> - 容器就像镜像的 **实例**。你可以用镜像来创建容器\n",
    "\n",
    "### 1.3 Docker 常用命令\n",
    "\n",
    "```bash\n",
    "# 查看所有 Docker 镜像\n",
    "docker images\n",
    "\n",
    "# 查看所有 Docker 容器\n",
    "docker ps -a\n",
    "\n",
    "# 删除 Docker 镜像\n",
    "docker rmi <image-name>\n",
    "\n",
    "# 删除 Docker 容器\n",
    "docker stop <container-name>\n",
    "docker rm <container-name>\n",
    "\n",
    "# 启动 Docker 容器\n",
    "docker start <container-name>\n",
    "\n",
    "# 重启 Docker 容器\n",
    "docker restart <container-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123ace7",
   "metadata": {},
   "source": [
    "\n",
    "## 2. 在 Docker 中使用 Spark\n",
    "\n",
    "### 2.1 在本地浏览器访问 Jupyter Lab \n",
    "\n",
    "由于我们在启动容器时已经配置了端口映射，因此可以通过 [http://localhost:9999](http://localhost:9999)，访问 Docker 容器中的 Jupyter Lab 应用。\n",
    "\n",
    "> 注意：进入 Jupyter Lab 需要 token，token 可以在 Docker 客户端的容器日志查看。\n",
    "\n",
    "### 2.2 检查 Spark 是否已安装\n",
    "\n",
    "打开 Jupyter Lab 的命令行界面，运行以下命令，检查 Spark 是否已安装：\n",
    "\n",
    "```bash\n",
    "echo $SPARK_HOME\n",
    "```\n",
    "\n",
    "### 2.3 启动 PySpark\n",
    "\n",
    "在命令行输入 `pyspark` 并回车，启动 pyspark。\n",
    "\n",
    "```bash\n",
    "pyspark\n",
    "```\n",
    "\n",
    "如果一切运行正常，你会看到以下界面：\n",
    "\n",
    "![pyspark-cmd](./img/pyspark-cmd.png)\n",
    "\n",
    "现在可以开始愉快地使用 Spark 啦！\n",
    "\n",
    "> 如果你想要一个既有 Hadoop 又有 Spark 的环境，可以参考：\n",
    "> \n",
    "> - [使用 Docker 快速部署 Spark + Hadoop 大数据集群](https://s1mple.cc/2021/10/12/使用-Docker-快速部署-Spark-Hadoop-大数据集群/)\n",
    "> - [bitnami/spark](https://github.com/bitnami/containers/tree/main/bitnami/spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d5aee-1626-488e-8ede-278701c4acd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
