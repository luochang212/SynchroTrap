{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89a65ee-3c3a-48af-81d6-272eb61d1720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T05:14:46.575246Z",
     "iopub.status.busy": "2024-07-30T05:14:46.574917Z",
     "iopub.status.idle": "2024-07-30T05:14:46.578735Z",
     "shell.execute_reply": "2024-07-30T05:14:46.578029Z",
     "shell.execute_reply.started": "2024-07-30T05:14:46.575220Z"
    }
   },
   "source": [
    "# 附录1：部署 Spark 环境\n",
    "\n",
    "虽然我们没有大公司那样的 Hadoop, Hive, Spark 基础设施，但在单机上运行 Spark 应用也并不困难。\n",
    "\n",
    "使用 [Docker](https://docs.docker.com/guides/) 是一个比较容易的方法。\n",
    "\n",
    "限于篇幅，我无法详述如何使用 Docker，假设你对 Docker 有一些基础的了解。\n",
    "\n",
    "> 对新手而言，一种常见情况是打开 Docker 的应用，却发现 Docker 不可用。\n",
    ">\n",
    "> 这是因为 Docker 是 客户端 / 服务端分离的。打开 Docker 桌面应用只是打开了 **客户端**，你还需要确保 **服务端** 也是开启的。来到命令行界面，运行：\n",
    ">\n",
    "> ```bash\n",
    "> docker --version\n",
    "> ```\n",
    ">\n",
    "> 来检查 Docker 服务端是否是已经启动。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db95999e-cffc-40af-b478-345fb154d934",
   "metadata": {},
   "source": [
    "## 1. Docker\n",
    "\n",
    "### 1.1 Docker 镜像\n",
    "\n",
    "把 [Dockerfile](https://github.com/jupyter/docker-stacks/blob/main/images/all-spark-notebook/Dockerfile) 复制到本地。然后，打开 Terminal 来到 Dockerfile 所在目录，运行以下代码构建镜像：\n",
    "\n",
    "```bash\n",
    "docker build -t spark-notebook-image .\n",
    "```\n",
    "\n",
    "注意，在中国大陆下载 Docker 镜像需要特殊的网络技巧。\n",
    "\n",
    "构建完成后，镜像信息可以在 Docker 桌面应用中查看。\n",
    "\n",
    "![docker-app](./img/docker-app.png)\n",
    "\n",
    "### 1.2 Docker 容器\n",
    "\n",
    "一旦镜像构建完成，你可以通过以下命令来启动一个容器：\n",
    "\n",
    "```bash\n",
    "# docker run -it --name <container-name> <image-name>\n",
    "# 运行选项：\n",
    "# -it: 用交互模式运行，这意味着你可以进入容器中\n",
    "# -d: 后台运行\n",
    "# -p <local-port>:<container-port>: 映射指定端口\n",
    "\n",
    "docker run -d --name spark-notebook-container -p 9999:8888 spark-notebook-image\n",
    "```\n",
    "\n",
    "Docker 镜像是可复制的，你可以在网络上把别人做好的 Docker 镜像复制到本地。\n",
    "\n",
    "但镜像无法直接被使用。要使用镜像，你需要先创建容器。容器就像镜像的 **实例**。一个镜像可以创建多个容器。\n",
    "\n",
    "```bash\n",
    "# 查看所有 Docker 镜像\n",
    "docker images\n",
    "\n",
    "# 查看所有 Docker 容器\n",
    "docker docker ps -a\n",
    "\n",
    "# 删除 Docker 镜像\n",
    "docker rmi <image-name>\n",
    "\n",
    "# 删除 Docker 容器\n",
    "docker stop <container-name>\n",
    "docker rm <container-name>\n",
    "```\n",
    "\n",
    "## 2. 启动 Jupyter Lab\n",
    "\n",
    "由于我们在启动 docker 时，已经配置了端口映射。\n",
    "\n",
    "在本地机器打开 [http://localhost:9999](http://localhost:9999) 可以直接访问容器的 Jupyter Lab。\n",
    "\n",
    "进入 Jupyter Lab 需要输入 token，这个 token 可以在 Docker 桌面应用的容器日志中找到。\n",
    "\n",
    "检查 Spark 是否已安装：\n",
    "\n",
    "```bash\n",
    "echo $SPARK_HOME\n",
    "```\n",
    "\n",
    "打开 Jupyter Lab 的 Terminal，输入 `pyspark` 回车，尝试启动 Spark：\n",
    "\n",
    "![pyspark-cmd](./img/pyspark-cmd.png)\n",
    "\n",
    "现在我们可以使用 pyspark 了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684793d0-ad21-4379-b32d-477526971f1d",
   "metadata": {},
   "source": [
    "如果想要一个有 Hadoop 和 Spark 的环境，可以尝试 [Marcel-Jan/docker-hadoop-spark](https://github.com/Marcel-Jan/docker-hadoop-spark/blob/master/docker-compose.yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d5aee-1626-488e-8ede-278701c4acd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
